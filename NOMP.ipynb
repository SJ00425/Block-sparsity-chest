{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1dab7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e35258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def db2lin(x_db): return 10.0**(x_db/10.0)\n",
    "def lin2db(x):    return 10.0*np.log10(x+1e-30)\n",
    "\n",
    "def steering_ula(phi, Nr, d_over_lambda=0.5):\n",
    "    m = np.arange(Nr)[:, None]\n",
    "    return np.exp(-1j*2*np.pi*d_over_lambda*m*np.sin(phi))  # (Nr,1)\n",
    "\n",
    "def delay_atom(k_idx, tau, f0):\n",
    "    k = k_idx[:, None]  # (Kp,1)\n",
    "    return np.exp(-1j*2*np.pi*f0*k*tau)  # (Kp,1)\n",
    "\n",
    "def doppler_atom(s_idx, nu, Tsym):\n",
    "    s = s_idx[:, None]  # (S,1)\n",
    "    return np.exp(1j*2*np.pi*nu*Tsym*s)  # (S,1)\n",
    "\n",
    "def complex_gaussian(shape, sigma2):\n",
    "    sigma = np.sqrt(max(sigma2, 0.0)/2.0)\n",
    "    return sigma*(np.random.randn(*shape)+1j*np.random.randn(*shape))\n",
    "\n",
    "def make_atom(phi, tau, nu, Nr, Kset, S, f0, Tsym, d_over_lambda=0.5):\n",
    "    \"\"\"Safe 3D rank-1 atom (Nr,Kp,S).\"\"\"\n",
    "    aphi = steering_ula(phi, Nr, d_over_lambda)          # (Nr,1)\n",
    "    atau_col = delay_atom(Kset, tau, f0)                 # (Kp,1)\n",
    "    anu_col  = doppler_atom(np.arange(S), nu, Tsym)      # (S,1)\n",
    "    M_phi_tau = aphi @ atau_col.T                        # (Nr,Kp)\n",
    "    atom = M_phi_tau[:, :, None] * anu_col[None, None, :, 0]  # (Nr,Kp,S)\n",
    "    return atom\n",
    "\n",
    "def nmse_db(H_true_list, H_est_list):\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "    for Ht, He in zip(H_true_list, H_est_list):\n",
    "        num += np.sum(np.abs(Ht - He)**2)\n",
    "        den += np.sum(np.abs(Ht)**2) + 1e-30\n",
    "    return 10*np.log10(num/den + 1e-30)\n",
    "\n",
    "\n",
    "\n",
    "def gen_perRB_gains(\n",
    "    N_RB, L,\n",
    "    base_mag=None,       # (L,)，路径的基准幅度；None 则随机递减\n",
    "    sigma_dB=3.0,        # 对数组阴影标准差[dB]\n",
    "    rho=0.9,             # RB 相关性（AR(1) 系数），越大越平滑\n",
    "    K_dB=None,           # Rician K 因子[dB]，None 表示纯 Rayleigh\n",
    "    seed=None\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if base_mag is None:\n",
    "        base_mag = np.sort(0.7+0.6*rng.random(L))[::-1]\n",
    "    base_mag = np.asarray(base_mag).reshape(L)\n",
    "\n",
    "    # 阴影：对数正态（每路径一条 AR(1) 轨迹）\n",
    "    sigma = sigma_dB/20*np.log(10)   # dB->对数域\n",
    "    log_s = np.zeros((N_RB, L))\n",
    "    eps = rng.standard_normal((N_RB, L))\n",
    "    for l in range(L):\n",
    "        for r in range(1, N_RB):\n",
    "            log_s[r, l] = rho*log_s[r-1, l] + np.sqrt(1-rho**2)*eps[r, l]\n",
    "    shadow = np.exp(sigma*log_s)  # (N_RB,L)\n",
    "\n",
    "    # 小尺度：Rayleigh 或 Rician\n",
    "    if K_dB is None:\n",
    "        # 纯 Rayleigh：相位均匀\n",
    "        phase = rng.uniform(-np.pi, np.pi, size=(N_RB, L))\n",
    "        mag   = base_mag[None, :]*shadow\n",
    "        g_rL  = mag * np.exp(1j*phase)\n",
    "    else:\n",
    "        K = 10**(np.asarray(K_dB).reshape(1, -1)/10.0) if np.ndim(K_dB) else 10**(K_dB/10.0)\n",
    "        if np.ndim(K_dB)==0: K = np.full((1, L), K)\n",
    "        # Rician: 直达分量 + 零均值复高斯分量\n",
    "        # 归一到 E|g|^2 ∝ base_mag^2；再乘上阴影\n",
    "        phase_LOS = rng.uniform(-np.pi, np.pi, size=(N_RB, L))\n",
    "        los = np.sqrt(K/(K+1)) * base_mag[None, :] * np.exp(1j*phase_LOS)\n",
    "        nlos_sigma = (base_mag[None, :]/np.sqrt(2*(K+1)))\n",
    "        nlos = nlos_sigma*(rng.standard_normal((N_RB, L)) + 1j*rng.standard_normal((N_RB, L)))\n",
    "        g_rL = (los + nlos) * shadow\n",
    "\n",
    "    return g_rL  # 形状 (N_RB, L)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Channel generation (Nt=1)  — supports manual truth\n",
    "# =========================\n",
    "\n",
    "def db2lin(x_db): return 10.0**(x_db/10.0)\n",
    "\n",
    "\n",
    "def steering_ula(phi, Nr, d_over_lambda=0.5):\n",
    "    m = np.arange(Nr)[:, None]\n",
    "    return np.exp(-1j*2*np.pi*d_over_lambda*m*np.sin(phi))  # (Nr,1)\n",
    "\n",
    "\n",
    "def make_atom(phi, tau, nu, Nr, Kset, S, f0, Tsym, d_over_lambda=0.5):\n",
    "    \"\"\"Safe 3D rank-1 atom (Nr,Kp,S).\"\"\"\n",
    "    aphi = steering_ula(phi, Nr, d_over_lambda)          # (Nr,1)\n",
    "    atau_col = delay_atom(Kset, tau, f0)                 # (Kp,1)\n",
    "    anu_col  = doppler_atom(np.arange(S), nu, Tsym)      # (S,1)\n",
    "    M_phi_tau = aphi @ atau_col.T                        # (Nr,Kp)\n",
    "    atom = M_phi_tau[:, :, None] * anu_col[None, None, :, 0]  # (Nr,Kp,S)\n",
    "    return atom\n",
    "\n",
    "\n",
    "def generate_multiRB_channel(\n",
    "    Nr=16, L=4, S=14, N_RB=128,\n",
    "    K_total=12, Kp=6,\n",
    "    f0=120e3, fc=10e9, c=3e8,\n",
    "    Tsym=None, SNR_dB=20.0,\n",
    "    d_over_lambda=0.5,\n",
    "    pilot_design=\"diverse\",\n",
    "    # ---- manual truth ----\n",
    "    phi_true=None, tau_true=None, nu_true=None,  # if None -> random\n",
    "    g_rL=None,       # shape (N_RB, L); if None -> synthesize from g_mag + random phases\n",
    "    g_mag=None,\n",
    "    g_model=None\n",
    "):\n",
    "    if Tsym is None:\n",
    "        Fs = f0*1024; cp_len = 6\n",
    "        Tsym = 1.0/f0 + cp_len/Fs\n",
    "\n",
    "    # large-scale truth\n",
    "    if phi_true is None:\n",
    "        phi_true = (np.random.uniform(-60, 60, size=L)*np.pi/180.0)\n",
    "    else:\n",
    "        phi_true = np.asarray(phi_true).reshape(L)\n",
    "    if tau_true is None:\n",
    "        tau_true = np.random.uniform(0.0, 1.0/f0, size=L)\n",
    "    else:\n",
    "        tau_true = np.asarray(tau_true).reshape(L)\n",
    "    if nu_true is None:\n",
    "        nu_true  = np.random.uniform(-0.45/Tsym, +0.45/Tsym, size=L)\n",
    "    else:\n",
    "        nu_true = np.asarray(nu_true).reshape(L)\n",
    "\n",
    "\n",
    "\n",
    "    if g_rL is not None:\n",
    "        g_rL = np.asarray(g_rL); assert g_rL.shape==(N_RB, L)\n",
    "        g_mag_out   = np.abs(g_rL).mean(axis=0)\n",
    "        g_phase_rL  = np.angle(g_rL)\n",
    "    else:\n",
    "        if g_mag is None:\n",
    "            # 使用统计模型自动生成（推荐默认）\n",
    "            gm = dict(sigma_dB=3.0, rho=0.9, K_dB=None, seed=None, base_mag=None)\n",
    "            if g_model is not None: gm.update(g_model)\n",
    "            g_rL = gen_perRB_gains(N_RB, L, **gm)\n",
    "            g_mag_out   = np.abs(g_rL).mean(axis=0)\n",
    "            g_phase_rL  = np.angle(g_rL)\n",
    "        else:\n",
    "            g_mag = np.asarray(g_mag)\n",
    "            if g_mag.ndim==1:\n",
    "                # All RB same amplitudde\n",
    "                phase = np.random.uniform(-np.pi, np.pi, size=(N_RB, L))\n",
    "                g_rL  = g_mag[None,:] * np.exp(1j*phase)\n",
    "                g_mag_out  = g_mag\n",
    "                g_phase_rL = np.angle(g_rL)\n",
    "            elif g_mag.ndim==2 and g_mag.shape==(N_RB, L):\n",
    "                phase = np.random.uniform(-np.pi, np.pi, size=(N_RB, L))\n",
    "                g_rL  = g_mag * np.exp(1j*phase)\n",
    "                g_mag_out  = g_mag.mean(axis=0)\n",
    "                g_phase_rL = np.angle(g_rL)\n",
    "            else:\n",
    "                raise ValueError(\"g_mag must be (L,) or (N_RB,L)\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    # subcarrier sets\n",
    "    all_k = np.arange(K_total)\n",
    "    Ksets = []\n",
    "    if pilot_design == \"fixed\":\n",
    "        base = np.linspace(0, K_total-1, Kp, dtype=int)\n",
    "        for _ in range(N_RB): Ksets.append(base.copy())\n",
    "    else:\n",
    "        for _ in range(N_RB):\n",
    "            Ksets.append(np.sort(np.random.choice(all_k, size=Kp, replace=False)))\n",
    "\n",
    "    Y_list = []\n",
    "    H_clean_list = []\n",
    "    SNR = db2lin(SNR_dB)\n",
    "\n",
    "    for r in range(N_RB):\n",
    "        Kset = Ksets[r]\n",
    "        H_r = np.zeros((Nr, Kp, S), dtype=complex)\n",
    "        for l in range(L):\n",
    "            atom = make_atom(phi_true[l], tau_true[l], nu_true[l],\n",
    "                             Nr, Kset, S, f0, Tsym, d_over_lambda)\n",
    "            H_r = H_r + g_rL[r, l] * atom\n",
    "        H_clean_list.append(H_r.copy())\n",
    "        sig_pow = np.mean(np.abs(H_r)**2)\n",
    "        N0 = sig_pow / SNR\n",
    "        Y_list.append(H_r + complex_gaussian(H_r.shape, N0))\n",
    "\n",
    "    true = dict(phi=phi_true, tau=tau_true, nu=nu_true,\n",
    "                g_mag=g_mag_out, g_phase_rL=g_phase_rL, g_rL=g_rL,\n",
    "                f0=f0, Tsym=Tsym, H_clean_list=H_clean_list)\n",
    "    return Y_list, Ksets, true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5302ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------- small helpers ----------\n",
    "def parabolic_peak_1d(vals, i):\n",
    "    N = len(vals)\n",
    "    if i<=0 or i>=N-1: return 0.0\n",
    "    y1,y2,y3 = vals[i-1], vals[i], vals[i+1]\n",
    "    denom = (y1 - 2*y2 + y3)\n",
    "    if np.abs(denom) < 1e-12: return 0.0\n",
    "    delta = 0.5*(y1 - y3)/denom\n",
    "    return float(np.clip(delta, -0.5, 0.5))\n",
    "\n",
    "\n",
    "# ---------- Non-Maximum Suppression, Suppress nearby secondary peaks ----------\n",
    "def nms3d(agg, w_phi=2, w_tau=2, w_nu=2, topK=32):\n",
    "    P, T, U = agg.shape\n",
    "    mask = np.ones_like(agg, dtype=bool)\n",
    "    peaks = []\n",
    "    flat_idx = np.argsort(agg.ravel())[::-1]\n",
    "    for idx in flat_idx:\n",
    "        if len(peaks) >= topK: break\n",
    "        p = idx // (T*U); t = (idx // U) % T; u = idx % U\n",
    "        if not mask[p,t,u]: continue\n",
    "        peaks.append((p,t,u, agg[p,t,u]))\n",
    "        p0,p1 = max(0, p-w_phi), min(P, p+w_phi+1)\n",
    "        t0,t1 = max(0, t-w_tau), min(T, t+w_tau+1)\n",
    "        u0,u1 = max(0, u-w_nu),  min(U, u+w_nu+1)\n",
    "        mask[p0:p1, t0:t1, u0:u1] = False\n",
    "    return peaks  # list of (i_phi,i_tau,i_nu,val)\n",
    "\n",
    "def grid_min_separation_ok(phi, tau, nu, S_list, mins):\n",
    "    for (p,t,n) in S_list:\n",
    "        if (abs(phi-p) < mins[0]) and (abs(tau-t) < mins[1]) and (abs(nu-n) < mins[2]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# Joint Multi-RB 3D-NOMP (tightened) + two-stage (global refine + final LS debias)\n",
    "# ======================================\n",
    "def joint_3d_nomp_multi_rb(\n",
    "    Y_list, Ksets, Nr, S, f0, Tsym,\n",
    "    K_max=12,\n",
    "    ov_phi=4, ov_tau=12, ov_nu=12,\n",
    "    d_over_lambda=0.5,\n",
    "    newton_iters=8,\n",
    "    nms_win=(2,2,2),\n",
    "    min_sep=None,            # if None, auto from f0/S/Tsym\n",
    "    stop_resid_drop=1e-2,\n",
    "    mdl_penalize_gains=True,\n",
    "    cfar_alpha=4.0,\n",
    "    rel_peak_floor=0.10,\n",
    "    do_final_debias=True,\n",
    "    do_global_refine=True,           # First phase of the two-phase approach: global loop refinement\n",
    "    global_refine_sweeps=1,          #  1~2\n",
    "    verbose=True\n",
    "):\n",
    "    # default min separation (rad, s, Hz)\n",
    "    if min_sep is None:\n",
    "        min_sep = (8*np.pi/180, 1.0/(8*f0), 1.0/(S*Tsym))\n",
    "\n",
    "    N_RB = len(Y_list)\n",
    "\n",
    "    # ===== Grids =====\n",
    "    Nphi = Nr*ov_phi\n",
    "    u = np.linspace(-1, 1, Nphi)\n",
    "    phi_grid = np.arcsin(np.clip(u, -1, 1))\n",
    "\n",
    "    Ntau = int(12*ov_tau)\n",
    "    tau_grid = np.linspace(0.0, 1.0/f0, Ntau, endpoint=False)\n",
    "\n",
    "    Nnu = S*ov_nu\n",
    "    nu_grid = np.linspace(-0.5/Tsym, 0.5/Tsym, Nnu, endpoint=False)\n",
    "\n",
    "    # ===== Dictionaries (AoA / Doppler are common to all RBs) =====\n",
    "    n_vec = np.arange(Nr)[:, None]\n",
    "    A_phi = np.exp(-1j*2*np.pi*d_over_lambda*n_vec*np.sin(phi_grid)[None, :])  # (Nr x Nphi)\n",
    "    colnorm_phi = np.sqrt((np.abs(A_phi)**2).sum(axis=0))\n",
    "    s_idx = np.arange(S)[:, None]\n",
    "    A_nu = np.exp(1j*2*np.pi*Tsym*s_idx*nu_grid[None, :])  # (S x Nnu)\n",
    "    colnorm_nu = np.sqrt((np.abs(A_nu)**2).sum(axis=0))\n",
    "\n",
    "    # Residuals\n",
    "    R_list = [Y.copy() for Y in Y_list]\n",
    "    N_obs = sum([np.prod(Y.shape) for Y in Y_list])  # total complex samples\n",
    "\n",
    "    phi_est, tau_est, nu_est = [], [], []\n",
    "    G_arr = None\n",
    "    residual_energy_trace = [np.sum([np.vdot(R, R).real for R in R_list])]\n",
    "    first_peak_val = None\n",
    "\n",
    "    # ---- per-RB delay dictionary cache ----\n",
    "    tau_cache = {}\n",
    "    def get_tau_dict(Kset):\n",
    "        key = tuple(Kset.tolist())\n",
    "        if key not in tau_cache:\n",
    "            k = Kset[:, None]\n",
    "            D = np.exp(-1j*2*np.pi*f0*k*tau_grid[None, :])  # (Kp,Ntau)\n",
    "            norms = np.sqrt((np.abs(D)**2).sum(axis=0))\n",
    "            tau_cache[key] = (D, norms)\n",
    "        return tau_cache[key]\n",
    "\n",
    "    # ---- aggregated correlation ----\n",
    "    def aggregated_correlation_cube():\n",
    "        agg = np.zeros((Nphi, Ntau, Nnu), dtype=float)\n",
    "        for r in range(N_RB):\n",
    "            R = R_list[r]\n",
    "            Kset = Ksets[r]\n",
    "            D_tau, norm_tau = get_tau_dict(Kset)\n",
    "            R2 = R.reshape(Nr, -1)                           # (Nr, Kp*S)\n",
    "            Z1 = A_phi.conj().T @ R2                         # (Nphi, Kp*S)\n",
    "            Z1 = Z1.reshape(Nphi, len(Kset), S)              # (Nphi, Kp, S)\n",
    "            Z2 = np.einsum('pks,kn->pns', Z1, D_tau.conj())  # (Nphi, Ntau, S)\n",
    "            C_r = np.einsum('pns,sq->pnq', Z2, A_nu.conj())  # (Nphi, Ntau, Nnu)\n",
    "            denom = (colnorm_phi[:,None,None] * norm_tau[None,:,None] * colnorm_nu[None,None,:] + 1e-12)\n",
    "            Cn = C_r / denom\n",
    "            agg += np.abs(Cn)**2\n",
    "        return agg\n",
    "\n",
    "    # ---- single-path per-RB LS gain ----\n",
    "    def ls_gain_per_RB(phi, tau, nu):\n",
    "        g_r = np.zeros(N_RB, dtype=complex)\n",
    "        for r in range(N_RB):\n",
    "            Kset = Ksets[r]\n",
    "            atom = make_atom(phi, tau, nu, Nr, Kset, S, f0, Tsym, d_over_lambda)\n",
    "            num  = np.vdot(atom, R_list[r])\n",
    "            den  = np.vdot(atom, atom).real + 1e-12\n",
    "            g_r[r] = num/den\n",
    "        return g_r\n",
    "\n",
    "    # ---- residual update ----\n",
    "    def subtract_path_from_residual(phi, tau, nu, g_r, sign=1.0):\n",
    "        for r in range(N_RB):\n",
    "            Kset = Ksets[r]\n",
    "            atom = make_atom(phi, tau, nu, Nr, Kset, S, f0, Tsym, d_over_lambda)\n",
    "            R_list[r] = R_list[r] - sign*g_r[r]*atom\n",
    "\n",
    "    # ---- coordinate-cycling Newton refinement (lightweight) ----\n",
    "    def refine_newton(phi, tau, nu, iters=newton_iters):\n",
    "        m = np.arange(Nr)[:, None]\n",
    "        s = np.arange(S)[:, None]\n",
    "        for _ in range(iters):\n",
    "            aphi = np.exp(-1j*2*np.pi*d_over_lambda*m*np.sin(phi))\n",
    "            dphi = aphi * (-1j*2*np.pi*d_over_lambda*m*np.cos(phi))\n",
    "            anu  = np.exp( 1j*2*np.pi*nu*Tsym*s)\n",
    "            dnu  = anu * ( 1j*2*np.pi*Tsym*s)\n",
    "\n",
    "            z_phi = 0+0j; z_nu = 0+0j\n",
    "            H_11 = 0.0;   H_22 = 0.0\n",
    "            for r in range(N_RB):\n",
    "                Kset = Ksets[r]\n",
    "                atau_col = np.exp(-1j*2*np.pi*f0*Kset[:, None]*tau)\n",
    "\n",
    "                v_m = np.einsum('mks,ks->m', R_list[r], (atau_col.conj() @ anu.conj().T))\n",
    "                z_phi += np.vdot(dphi[:,0], v_m)\n",
    "\n",
    "                w_s = np.einsum('mks,mk->s', R_list[r], (aphi.conj() @ atau_col.conj().T))\n",
    "                z_nu  += np.vdot(dnu[:,0], w_s)\n",
    "\n",
    "                H_11 += np.vdot(dphi[:,0], dphi[:,0]).real * (atau_col.size * S)\n",
    "                H_22 += np.vdot(dnu[:,0],  dnu[:,0]).real  * (Nr * len(Kset))\n",
    "\n",
    "            eps = 1e-6\n",
    "            damp = 0.35\n",
    "            phi = np.clip(phi + damp*(z_phi.conjugate()).real/(H_11+eps), -np.pi/2+1e-6, np.pi/2-1e-6)\n",
    "            nu  = np.clip(nu  + damp*(z_nu.conjugate()).real /(H_22+eps), -0.5/Tsym, +0.5/Tsym)\n",
    "\n",
    "            # tau step\n",
    "            num = 0+0j; den = 0.0\n",
    "            for r in range(N_RB):\n",
    "                Kset = Ksets[r]\n",
    "                atau_col = np.exp(-1j*2*np.pi*f0*Kset[:, None]*tau)\n",
    "                d_at_col = atau_col * (-1j*2*np.pi*f0*Kset[:, None])\n",
    "\n",
    "                A1 = aphi; AN = anu.T\n",
    "                M0 = (A1 @ atau_col.T);  A0 = M0[:, :, None] * AN[None, None, :]\n",
    "                M1 = (A1 @ d_at_col.T);  A1_tau = M1[:, :, None] * AN[None, None, :]\n",
    "\n",
    "                q   = np.vdot(A0,     R_list[r])\n",
    "                q_p = np.vdot(A1_tau, R_list[r])\n",
    "\n",
    "                num += (q.conjugate()*q_p)\n",
    "                den += (np.abs(q_p)**2 + 1e-12)\n",
    "\n",
    "            tau = np.clip(tau + 0.5*(2.0*num.real)/(2.0*den + 1e-12), 0.0, 1.0/f0 - 1e-12)\n",
    "        return phi, tau, nu\n",
    "\n",
    "    # ---- sweep refinement over all detected paths ----\n",
    "    def cyclic_refine_sweep():\n",
    "        K = len(phi_est)\n",
    "        if K==0: return\n",
    "        for i in range(K):\n",
    "            gi = G_arr[:, i].copy()\n",
    "            subtract_path_from_residual(phi_est[i], tau_est[i], nu_est[i], gi, sign=-1.0)  # add back\n",
    "            pr, tr, nr = refine_newton(phi_est[i], tau_est[i], nu_est[i])\n",
    "            gi_new = ls_gain_per_RB(pr, tr, nr)\n",
    "            subtract_path_from_residual(pr, tr, nr, gi_new, sign=+1.0)\n",
    "            phi_est[i], tau_est[i], nu_est[i] = pr, tr, nr\n",
    "            G_arr[:, i] = gi_new\n",
    "\n",
    "    # ---- merge near-duplicates ----\n",
    "    def merge_nearby_paths():\n",
    "        nonlocal G_arr, phi_est, tau_est, nu_est\n",
    "        if G_arr is None or G_arr.shape[1] <= 1: return\n",
    "        K = G_arr.shape[1]\n",
    "        keep = np.ones(K, dtype=bool)\n",
    "        power = np.sum(np.abs(G_arr)**2, axis=0)\n",
    "        for i in range(K):\n",
    "            if not keep[i]: continue\n",
    "            for j in range(i+1, K):\n",
    "                if not keep[j]: continue\n",
    "                if (abs(phi_est[i]-phi_est[j]) < min_sep[0] and\n",
    "                    abs(tau_est[i]-tau_est[j]) < min_sep[1] and\n",
    "                    abs(nu_est [i]-nu_est [j]) < min_sep[2]):\n",
    "                    if power[i] >= power[j]:\n",
    "                        keep[j] = False\n",
    "                    else:\n",
    "                        keep[i] = False\n",
    "                        break\n",
    "        phi_est = list(np.array(phi_est)[keep])\n",
    "        tau_est = list(np.array(tau_est)[keep])\n",
    "        nu_est  = list(np.array(nu_est )[keep])\n",
    "        G_arr   = G_arr[:, keep]\n",
    "\n",
    "    # ---- FINAL joint LS debias per RB ----\n",
    "    def final_joint_ls_debias(phi_arr, tau_arr, nu_arr):\n",
    "        \"\"\"Return G_ls (N_RB x K) and final residual list.\"\"\"\n",
    "        K = len(phi_arr)\n",
    "        if K == 0:\n",
    "            return np.zeros((N_RB, 0), dtype=complex), [Y.copy() for Y in Y_list]\n",
    "        G_ls = np.zeros((N_RB, K), dtype=complex)\n",
    "        R_final = []\n",
    "        for r in range(N_RB):\n",
    "            Kset = Ksets[r]\n",
    "            # Build design matrix A_r: (Nr*Kp*S) x K\n",
    "            Acols = []\n",
    "            for k in range(K):\n",
    "                atom = make_atom(phi_arr[k], tau_arr[k], nu_arr[k], Nr, Kset, S, f0, Tsym, d_over_lambda)\n",
    "                Acols.append(atom.reshape(-1))\n",
    "            A_r = np.stack(Acols, axis=1)  # (N, K)\n",
    "            y_r = Y_list[r].reshape(-1)\n",
    "            # Least squares solve\n",
    "            g_r, *_ = np.linalg.lstsq(A_r, y_r, rcond=None)\n",
    "            G_ls[r, :] = g_r\n",
    "            # residual\n",
    "            y_hat = A_r @ g_r\n",
    "            R_final.append((y_r - y_hat).reshape(Nr, len(Kset), S))\n",
    "        return G_ls, R_final\n",
    "\n",
    "    # ---------- MAIN detection ----------\n",
    "    last_E = residual_energy_trace[-1]\n",
    "    for k in range(K_max):\n",
    "        \n",
    "        # ---------- coarse search ----------\n",
    "        agg = aggregated_correlation_cube()\n",
    "\n",
    "        # CFAR/GLRT gate\n",
    "        med = np.median(agg)\n",
    "        std = np.std(agg)\n",
    "        th  = med + cfar_alpha*std\n",
    "        ip, it, iu = np.unravel_index(np.argmax(agg), agg.shape)\n",
    "        peak_now = agg[ip,it,iu]\n",
    "        if first_peak_val is None:\n",
    "            first_peak_val = peak_now\n",
    "        if (peak_now < th) or (peak_now < rel_peak_floor*first_peak_val):\n",
    "            if verbose: print(f\"Stop by CFAR: peak={peak_now:.2e} < max({th:.2e}, {rel_peak_floor:.2f}*first)\")\n",
    "            break\n",
    "\n",
    "        cand = nms3d(agg, w_phi=nms_win[0], w_tau=nms_win[1], w_nu=nms_win[2], topK=16)\n",
    "        chosen = None\n",
    "        for (ip,it,iu,val) in cand:\n",
    "            if (val < th) or (val < rel_peak_floor*first_peak_val):\n",
    "                continue\n",
    "            dphi = parabolic_peak_1d(agg[:,it,iu], ip)\n",
    "            dtau = parabolic_peak_1d(agg[ip,:,iu], it)\n",
    "            dnu  = parabolic_peak_1d(agg[ip,it,:], iu)\n",
    "            phi0 = phi_grid[np.clip(ip,1,Nphi-2)] + dphi*(phi_grid[1]-phi_grid[0])\n",
    "            tau0 = tau_grid[np.clip(it,1,Ntau-2)] + dtau*(tau_grid[1]-tau_grid[0])\n",
    "            nu0  = nu_grid [np.clip(iu,1,Nnu -2)] + dnu *(nu_grid[1] -nu_grid[0] )\n",
    "            if grid_min_separation_ok(phi0, tau0, nu0,\n",
    "                                      list(zip(phi_est,tau_est,nu_est)),\n",
    "                                      mins=min_sep):\n",
    "                chosen = (phi0, tau0, nu0, val); break\n",
    "        if chosen is None:\n",
    "            if verbose: print(\"Stop: no candidate passes NMS+CFAR+min-sep.\")\n",
    "            break\n",
    "\n",
    "        phi0,tau0,nu0,_ = chosen\n",
    "        if verbose: print(f\"[Search] k={k+1} init: phi={phi0*180/np.pi:.2f}deg\")\n",
    "\n",
    "\n",
    "        # ---------- refine_newton ----------\n",
    "        pr, tr, nr = refine_newton(phi0, tau0, nu0)\n",
    "        gr = ls_gain_per_RB(pr, tr, nr)\n",
    "        subtract_path_from_residual(pr, tr, nr, gr)\n",
    "\n",
    "        phi_est.append(pr); tau_est.append(tr); nu_est.append(nr)\n",
    "        G_arr = gr[:,None] if (G_arr is None) else np.concatenate([G_arr, gr[:,None]], axis=1)\n",
    "\n",
    "        merge_nearby_paths()\n",
    "\n",
    "        Eres = np.sum([np.vdot(R, R).real for R in R_list])\n",
    "        rel_drop = (last_E - Eres) / (last_E + 1e-12)\n",
    "        residual_energy_trace.append(Eres)\n",
    "        last_E = Eres\n",
    "        if rel_drop < stop_resid_drop:\n",
    "            if verbose: print(f\"Stop by residual-drop: ΔE/E={rel_drop:.2e}\")\n",
    "            break\n",
    "\n",
    "        if (len(phi_est)) % 2 == 0:\n",
    "            cyclic_refine_sweep()\n",
    "            merge_nearby_paths()\n",
    "\n",
    "    # ---- MDL Minimum Description Length (count per-RB complex gains) ----\n",
    "    if len(residual_energy_trace) <= 1 or G_arr is None:\n",
    "        return dict(phi=np.array([]), tau=np.array([]), nu=np.array([]),\n",
    "                    G=np.zeros((len(Y_list),0), dtype=complex),\n",
    "                    R_list=[Y.copy() for Y in Y_list])\n",
    "\n",
    "    mdl = []\n",
    "    for kk in range(1, G_arr.shape[1]+1):\n",
    "        sigma2 = residual_energy_trace[min(kk, len(residual_energy_trace)-1)]/N_obs\n",
    "        if mdl_penalize_gains:\n",
    "            p_k = kk*(3 + 2*len(Y_list))   # 3 shared + 2*N_RB (complex gain)\n",
    "        else:\n",
    "            p_k = kk*3\n",
    "        mdl_k = N_obs*np.log(max(sigma2,1e-20)) + 0.5*p_k*np.log(N_obs)\n",
    "        mdl.append(mdl_k)\n",
    "    k_opt = int(np.argmin(mdl)) + 1\n",
    "\n",
    "    # truncate to k_opt\n",
    "    phi_est = np.array(phi_est[:k_opt])\n",
    "    tau_est = np.array(tau_est[:k_opt])\n",
    "    nu_est  = np.array(nu_est [:k_opt])\n",
    "    G_arr   = G_arr[:, :k_opt]\n",
    "\n",
    "    # ===== 二段式：阶段A —— 全局循环重细化（可选）=====\n",
    "    if do_global_refine and k_opt > 0:\n",
    "        if verbose: print(f\"[Global-Refine] {global_refine_sweeps} sweep(s) over {k_opt} paths...\")\n",
    "        for _ in range(global_refine_sweeps):\n",
    "            for i in range(k_opt):\n",
    "                gi = G_arr[:, i].copy()\n",
    "                # add back this path\n",
    "                subtract_path_from_residual(phi_est[i], tau_est[i], nu_est[i], gi, sign=-1.0)\n",
    "                # refine parameters under current interference model\n",
    "                pr, tr, nr = refine_newton(phi_est[i], tau_est[i], nu_est[i])\n",
    "                # LS gains per RB and subtract again\n",
    "                gi_new = ls_gain_per_RB(pr, tr, nr)\n",
    "                subtract_path_from_residual(pr, tr, nr, gi_new, sign=+1.0)\n",
    "                # commit\n",
    "                phi_est[i], tau_est[i], nu_est[i] = pr, tr, nr\n",
    "                G_arr[:, i] = gi_new\n",
    "\n",
    "    # ===== 二段式：阶段B —— 最终 per-RB 联合 LS 去偏 =====\n",
    "    if do_final_debias:\n",
    "        if verbose: print(\"[Debias] Running per-RB joint LS debias...\")\n",
    "        G_ls, R_final = final_joint_ls_debias(phi_est, tau_est, nu_est)\n",
    "        return dict(phi=phi_est, tau=tau_est, nu=nu_est, G=G_ls, R_list=R_final)\n",
    "    else:\n",
    "        # reconstruct residuals using current G_arr\n",
    "        R_final = [Y.copy() for Y in Y_list]\n",
    "        for i in range(k_opt):\n",
    "            subtract_path_from_residual(phi_est[i], tau_est[i], nu_est[i], G_arr[:, i], sign=+1.0)\n",
    "        return dict(phi=phi_est, tau=tau_est, nu=nu_est, G=G_arr, R_list=R_final)\n",
    "\n",
    "# =========================\n",
    "# Reconstruction for NMSE\n",
    "# =========================\n",
    "def reconstruct_channel_list(phi, tau, nu, G, Ksets, Nr, S, f0, Tsym, d_over_lambda=0.5):\n",
    "    \"\"\"\n",
    "    Build H_est per RB from estimated params and per-RB gains.\n",
    "    phi/tau/nu: (K,)\n",
    "    G: (N_RB x K)\n",
    "    returns: list of (Nr x Kp x S)\n",
    "    \"\"\"\n",
    "    K = len(phi)\n",
    "    N_RB = G.shape[0] if G.ndim==2 else 0\n",
    "    H_est_list = []\n",
    "    for r in range(N_RB):\n",
    "        Kset = Ksets[r]\n",
    "        Nr_local = Nr\n",
    "        H_r = np.zeros((Nr_local, len(Kset), S), dtype=complex)\n",
    "        for k in range(K):\n",
    "            if G[r, k] == 0: continue\n",
    "            atom = make_atom(phi[k], tau[k], nu[k], Nr, Kset, S, f0, Tsym, d_over_lambda)\n",
    "            H_r += G[r, k] * atom\n",
    "        H_est_list.append(H_r)\n",
    "    return H_est_list\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7dd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "Nr = 16\n",
    "L_true = 4\n",
    "S = 14\n",
    "N_RB = 64        \n",
    "K_total = 12 # scs number in one RB\n",
    "Kp = 12         \n",
    "f0 = 120e3\n",
    "Fs = f0*1024 # sample rate\n",
    "cp_len = 6\n",
    "Tsym = 1.0/f0 + cp_len/Fs\n",
    "SNR_dB = 20.0\n",
    "\n",
    "# ===== manual truth =====\n",
    "phi_deg_man = np.array([6.0, 26.0, 12.0, 33.0])\n",
    "tau_us_man  = np.array([3.53, 5.382, 3.65, 7.43])\n",
    "nu_hz_man   = np.array([5.0e4, -1.25e4, 3.13e4, 3.1e3])\n",
    "\n",
    "phi_true_in = phi_deg_man*np.pi/180.0\n",
    "tau_true_in = tau_us_man*1e-6\n",
    "nu_true_in  = nu_hz_man\n",
    "\n",
    "# g_mag_in = np.clip(np.array([1.2,0.9,0.6,0.4])[None,:] * (1 + 0.2*np.random.randn(8,4)), 1e-5, None) # RB-specific magnitudes, random phase:\n",
    "# g_mag_in = np.array([1.2, 1, 0.8, 0.6])  # (L,) # Shared magnitudes, random phase:\n",
    "\n",
    "g_rL_in = gen_perRB_gains(N_RB=8, L=4, base_mag=[1.2,0.9,0.6,0.4], sigma_dB=2.5, rho=0.8, seed=1)\n",
    "g_model=dict(base_mag=[1.2,0.9,0.6,0.4], sigma_dB=3, rho=0.9, K_dB=None, seed=0)  # Fully specified complex gains:\n",
    "\n",
    "Y_list, Ksets, truth = generate_multiRB_channel(\n",
    "    Nr=Nr, L=L_true, S=S, N_RB=N_RB,\n",
    "    K_total=K_total, Kp=Kp, f0=f0, Tsym=Tsym,\n",
    "    SNR_dB=SNR_dB, pilot_design=\"fixed\",\n",
    "    phi_true=phi_true_in, tau_true=tau_true_in, nu_true=nu_true_in,\n",
    "    g_model=g_model,\n",
    "    # g_rL=g_rL_in, \n",
    "    # g_mag=g_mag_in\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e8f53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search] k=1 init: phi=3.50deg\n",
      "[Search] k=2 init: phi=29.60deg\n",
      "[Search] k=3 init: phi=12.67deg\n",
      "[Search] k=4 init: phi=29.00deg\n",
      "[Search] k=5 init: phi=20.87deg\n",
      "Stop: no candidate passes NMS+CFAR+min-sep.\n",
      "[Global-Refine] 2 sweep(s) over 5 paths...\n",
      "[Debias] Running per-RB joint LS debias...\n",
      "\n",
      "=== Ground Truth vs Estimate (unordered) ===\n",
      "phi_true [deg]: [ 6. 26. 12. 33.]\n",
      "tau_true [us] : [3.53  5.382 3.65  7.43 ]\n",
      "nu_true  [Hz] : [ 50000. -12500.  31300.   3100.]\n",
      "\n",
      "phi_est  [deg]: [ 4.51 28.82 12.65 29.92 20.46]\n",
      "tau_est  [us] : [3.53  5.382 3.65  7.43  5.382]\n",
      "nu_est   [Hz] : [ 49721.937 -12382.944  31412.904   3137.325  -9408.658]\n",
      "\n",
      "--- Per-RB gains (magnitudes, debiased) ---\n",
      "RB #00 | |g_true_r|:, [1.2 0.9 0.6 0.4]  | |g_est|: [1.112 0.744 0.576 0.317 0.286]\n",
      "RB #01 | |g_true_r|:, [1.107 0.95  0.73  0.461]  | |g_est|: [1.029 0.783 0.723 0.371 0.3  ]\n",
      "RB #02 | |g_true_r|:, [1.004 0.781 0.652 0.458]  | |g_est|: [0.928 0.641 0.632 0.367 0.255]\n",
      "RB #03 | |g_true_r|:, [0.72  0.767 0.536 0.404]  | |g_est|: [0.671 0.633 0.529 0.321 0.247]\n",
      "RB #04 | |g_true_r|:, [0.698 0.743 0.577 0.473]  | |g_est|: [0.654 0.616 0.575 0.377 0.236]\n",
      "RB #05 | |g_true_r|:, [0.723 0.93  0.524 0.49 ]  | |g_est|: [0.673 0.77  0.52  0.389 0.301]\n",
      "RB #06 | |g_true_r|:, [0.871 0.94  0.475 0.418]  | |g_est|: [0.808 0.779 0.457 0.331 0.3  ]\n",
      "RB #07 | |g_true_r|:, [0.84  0.968 0.417 0.403]  | |g_est|: [0.779 0.797 0.401 0.319 0.312]\n",
      "RB #08 | |g_true_r|:, [0.85  1.042 0.447 0.425]  | |g_est|: [0.791 0.861 0.436 0.332 0.336]\n",
      "RB #09 | |g_true_r|:, [0.797 1.007 0.518 0.529]  | |g_est|: [0.735 0.831 0.501 0.414 0.324]\n",
      "RB #10 | |g_true_r|:, [0.687 1.251 0.644 0.579]  | |g_est|: [0.638 1.036 0.63  0.46  0.402]\n",
      "RB #11 | |g_true_r|:, [0.756 1.155 0.796 0.749]  | |g_est|: [0.698 0.953 0.77  0.598 0.376]\n",
      "RB #12 | |g_true_r|:, [1.038 1.373 0.817 0.587]  | |g_est|: [0.966 1.136 0.796 0.462 0.447]\n",
      "RB #13 | |g_true_r|:, [1.053 1.453 0.652 0.599]  | |g_est|: [0.979 1.2   0.654 0.474 0.465]\n",
      "RB #14 | |g_true_r|:, [1.138 1.538 0.541 0.521]  | |g_est|: [1.066 1.272 0.548 0.415 0.496]\n",
      "RB #15 | |g_true_r|:, [1.071 1.222 0.711 0.471]  | |g_est|: [1.002 1.011 0.715 0.376 0.396]\n",
      "RB #16 | |g_true_r|:, [1.138 1.14  0.887 0.565]  | |g_est|: [1.061 0.94  0.89  0.448 0.365]\n",
      "RB #17 | |g_true_r|:, [1.259 0.799 0.86  0.605]  | |g_est|: [1.167 0.658 0.833 0.482 0.256]\n",
      "RB #18 | |g_true_r|:, [1.457 0.737 1.091 0.476]  | |g_est|: [1.349 0.61  1.062 0.379 0.237]\n",
      "RB #19 | |g_true_r|:, [1.294 0.865 1.035 0.632]  | |g_est|: [1.198 0.713 1.001 0.503 0.279]\n",
      "RB #20 | |g_true_r|:, [1.321 0.79  0.926 0.512]  | |g_est|: [1.222 0.655 0.896 0.408 0.255]\n",
      "RB #21 | |g_true_r|:, [1.08  0.88  0.968 0.607]  | |g_est|: [1.01  0.725 0.967 0.481 0.285]\n",
      "RB #22 | |g_true_r|:, [0.974 1.137 0.884 0.738]  | |g_est|: [0.906 0.94  0.866 0.588 0.364]\n",
      "RB #23 | |g_true_r|:, [0.932 0.994 0.883 0.811]  | |g_est|: [0.871 0.822 0.88  0.643 0.317]\n",
      "RB #24 | |g_true_r|:, [0.979 0.901 0.694 0.612]  | |g_est|: [0.909 0.745 0.693 0.484 0.289]\n",
      "RB #25 | |g_true_r|:, [1.078 1.046 0.667 0.499]  | |g_est|: [1.    0.863 0.664 0.398 0.338]\n",
      "RB #26 | |g_true_r|:, [1.242 0.85  0.593 0.536]  | |g_est|: [1.153 0.699 0.579 0.425 0.271]\n",
      "RB #27 | |g_true_r|:, [0.882 0.906 0.544 0.529]  | |g_est|: [0.817 0.75  0.542 0.421 0.29 ]\n",
      "RB #28 | |g_true_r|:, [0.9   0.933 0.61  0.459]  | |g_est|: [0.836 0.77  0.589 0.365 0.3  ]\n",
      "RB #29 | |g_true_r|:, [1.147 1.037 0.691 0.539]  | |g_est|: [1.064 0.859 0.669 0.428 0.334]\n",
      "RB #30 | |g_true_r|:, [1.297 1.161 0.689 0.422]  | |g_est|: [1.204 0.962 0.66  0.338 0.375]\n",
      "RB #31 | |g_true_r|:, [1.261 1.008 0.549 0.437]  | |g_est|: [1.174 0.835 0.545 0.349 0.324]\n",
      "RB #32 | |g_true_r|:, [1.152 0.854 0.473 0.451]  | |g_est|: [1.07  0.705 0.451 0.358 0.27 ]\n",
      "RB #33 | |g_true_r|:, [1.221 1.047 0.484 0.521]  | |g_est|: [1.134 0.865 0.484 0.415 0.335]\n",
      "RB #34 | |g_true_r|:, [1.505 1.227 0.346 0.611]  | |g_est|: [1.402 1.012 0.353 0.482 0.397]\n",
      "RB #35 | |g_true_r|:, [1.549 1.267 0.387 0.62 ]  | |g_est|: [1.445 1.041 0.362 0.492 0.408]\n",
      "RB #36 | |g_true_r|:, [1.584 1.16  0.303 0.584]  | |g_est|: [1.472 0.956 0.288 0.461 0.375]\n",
      "RB #37 | |g_true_r|:, [1.365 1.331 0.311 0.569]  | |g_est|: [1.271 1.101 0.295 0.454 0.424]\n",
      "RB #38 | |g_true_r|:, [1.186 1.185 0.332 0.439]  | |g_est|: [1.101 0.978 0.333 0.346 0.383]\n",
      "RB #39 | |g_true_r|:, [1.242 1.135 0.294 0.303]  | |g_est|: [1.154 0.937 0.309 0.242 0.365]\n",
      "RB #40 | |g_true_r|:, [1.337 1.06  0.292 0.301]  | |g_est|: [1.241 0.878 0.268 0.239 0.339]\n",
      "RB #41 | |g_true_r|:, [1.739 1.035 0.318 0.248]  | |g_est|: [1.617 0.855 0.311 0.199 0.332]\n",
      "RB #42 | |g_true_r|:, [2.147 1.172 0.398 0.262]  | |g_est|: [1.99  0.972 0.356 0.208 0.373]\n",
      "RB #43 | |g_true_r|:, [2.326 1.207 0.454 0.267]  | |g_est|: [2.158 0.998 0.418 0.216 0.388]\n",
      "RB #44 | |g_true_r|:, [1.744 1.368 0.349 0.268]  | |g_est|: [1.619 1.131 0.365 0.212 0.443]\n",
      "RB #45 | |g_true_r|:, [1.629 1.122 0.404 0.271]  | |g_est|: [1.513 0.925 0.425 0.212 0.366]\n",
      "RB #46 | |g_true_r|:, [1.479 1.187 0.391 0.347]  | |g_est|: [1.374 0.979 0.398 0.276 0.381]\n",
      "RB #47 | |g_true_r|:, [1.527 1.075 0.305 0.289]  | |g_est|: [1.426 0.89  0.304 0.232 0.343]\n",
      "RB #48 | |g_true_r|:, [1.756 1.048 0.313 0.382]  | |g_est|: [1.631 0.867 0.306 0.296 0.337]\n",
      "RB #49 | |g_true_r|:, [1.393 0.945 0.311 0.419]  | |g_est|: [1.297 0.779 0.329 0.333 0.301]\n",
      "RB #50 | |g_true_r|:, [1.242 0.857 0.261 0.466]  | |g_est|: [1.155 0.709 0.273 0.363 0.278]\n",
      "RB #51 | |g_true_r|:, [1.398 0.802 0.29  0.378]  | |g_est|: [1.306 0.66  0.304 0.299 0.256]\n",
      "RB #52 | |g_true_r|:, [1.282 0.998 0.319 0.538]  | |g_est|: [1.194 0.83  0.319 0.433 0.321]\n",
      "RB #53 | |g_true_r|:, [1.131 1.078 0.33  0.569]  | |g_est|: [1.053 0.894 0.338 0.456 0.346]\n",
      "RB #54 | |g_true_r|:, [1.137 0.973 0.307 0.871]  | |g_est|: [1.055 0.805 0.289 0.692 0.313]\n",
      "RB #55 | |g_true_r|:, [1.13  0.713 0.298 0.892]  | |g_est|: [1.046 0.59  0.29  0.706 0.229]\n",
      "RB #56 | |g_true_r|:, [1.054 0.895 0.371 0.805]  | |g_est|: [0.982 0.737 0.369 0.639 0.29 ]\n",
      "RB #57 | |g_true_r|:, [0.995 0.77  0.351 0.601]  | |g_est|: [0.924 0.635 0.35  0.478 0.248]\n",
      "RB #58 | |g_true_r|:, [1.215 0.994 0.306 0.483]  | |g_est|: [1.127 0.825 0.302 0.385 0.324]\n",
      "RB #59 | |g_true_r|:, [0.93  0.851 0.205 0.399]  | |g_est|: [0.862 0.703 0.197 0.316 0.27 ]\n",
      "RB #60 | |g_true_r|:, [1.159 0.812 0.26  0.371]  | |g_est|: [1.082 0.671 0.272 0.294 0.264]\n",
      "RB #61 | |g_true_r|:, [1.517 0.846 0.267 0.549]  | |g_est|: [1.41  0.701 0.285 0.438 0.263]\n",
      "RB #62 | |g_true_r|:, [1.411 0.708 0.298 0.529]  | |g_est|: [1.31  0.584 0.309 0.421 0.225]\n",
      "RB #63 | |g_true_r|:, [1.63  0.631 0.361 0.585]  | |g_est|: [1.517 0.526 0.365 0.463 0.202]\n",
      "\n",
      "NMSE (dB) vs clean channel: -7.48 dB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "est = joint_3d_nomp_multi_rb(\n",
    "    Y_list, Ksets, Nr=Nr, S=S, f0=f0, Tsym=Tsym,\n",
    "    K_max=8, ov_phi=4, ov_tau=16, ov_nu=16,\n",
    "    newton_iters=8, verbose=True,\n",
    "    nms_win=(2,2,2),\n",
    "    min_sep=(8*np.pi/180, 1.0/(12*f0), 1.0/(S*Tsym)),   # tighter delay sep for Kp=12\n",
    "    stop_resid_drop=1e-2,\n",
    "    mdl_penalize_gains=True,\n",
    "    cfar_alpha=4.0,\n",
    "    rel_peak_floor=0.10,\n",
    "    do_final_debias=True,\n",
    "    do_global_refine=True,        # two-stage \"Phase A\"\n",
    "    global_refine_sweeps=2\n",
    ")\n",
    "\n",
    "def deg(x): return x*180/np.pi\n",
    "print(\"\\n=== Ground Truth vs Estimate (unordered) ===\")\n",
    "print(\"phi_true [deg]:\", np.round(deg(truth[\"phi\"]), 2))\n",
    "print(\"tau_true [us] :\", np.round(1e6*truth[\"tau\"], 3))\n",
    "print(\"nu_true  [Hz] :\", np.round(truth[\"nu\"], 3))\n",
    "\n",
    "print(\"\\nphi_est  [deg]:\", np.round(deg(est[\"phi\"]), 2))\n",
    "print(\"tau_est  [us] :\", np.round(1e6*est[\"tau\"], 3))\n",
    "print(\"nu_est   [Hz] :\", np.round(est[\"nu\"], 3))\n",
    "\n",
    "# ========== Per-RB gains ==========\n",
    "if est[\"G\"].shape[1] > 0:\n",
    "    print(\"\\n--- Per-RB gains (magnitudes, debiased) ---\")\n",
    "    G_true_abs = np.abs(truth[\"g_rL\"])   # (N_RB, L_true)\n",
    "    G_est_abs  = np.abs(est[\"G\"])        # (N_RB, K_est)\n",
    "    for r in range(N_RB):\n",
    "        print(f\"RB #{r:02d} | |g_true_r|:, {np.round(np.abs(truth['g_rL'][r]), 3)}  | |g_est|: {np.round(G_est_abs[r],3)}\")\n",
    "\n",
    "    # for r in range(N_RB):\n",
    "        # print(f\"RB #{r:02d} | |g_true|: {np.round(G_true_abs[r],3)} | |g_est|: {np.round(G_est_abs[r],3)}\")\n",
    "    # for r in range(N_RB):\n",
    "    #     print(f\"RB #{r:02d} | g_true: {np.round(truth['g_rL'][r],3)} | g_est: {np.round(est['G'][r],3)}\")\n",
    "\n",
    "# ========== NMSE(dB)（relative to no noise H_clean）==========\n",
    "H_est_list = reconstruct_channel_list(est[\"phi\"], est[\"tau\"], est[\"nu\"], est[\"G\"],\n",
    "                                        Ksets, Nr, S, f0, Tsym)\n",
    "nmse_val_db = nmse_db(truth[\"H_clean_list\"], H_est_list)\n",
    "print(f\"\\nNMSE (dB) vs clean channel: {nmse_val_db:.2f} dB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionna_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
